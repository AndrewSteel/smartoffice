
# ğŸ§  SmartOffice

SmartOffice ist eine modulare, KI-gestÃ¼tzte Plattform zur digitalen Verwaltung von Dokumenten, Bildern und anderen relevanten Informationen â€“ lokal, hybrid oder in der Cloud.
Ziel ist es, ein vollstÃ¤ndig integriertes, intelligentes System fÃ¼r das papierlose BÃ¼ro der Zukunft zu schaffen â€“ technisch schlank, erweiterbar und datenschutzfreundlich.

---

## ğŸš€ Komponenten

| Dienst          | Funktion                                     |
|-----------------|----------------------------------------------|
| `backend`        | FastAPI-Server zum Hochladen & Steuern      |
| `ollama-client`  | Subscribt per MQTT und generiert Bildbeschreibung mit Ollama |
| `ollama`         | LLM-Modellserver (z.â€¯B. mit LLaVA)           |
| `mqtt` (Mosquitto) | Message Broker zur Verarbeitung             |
| `mongo`          | Speicherung der Metadaten                   |

---

## âš™ï¸ Setup & Start

### ğŸ” Voraussetzung

- **Docker & Docker Compose** installiert
- Optional: **NVIDIA GPU + Container Toolkit** fÃ¼r GPU-Beschleunigung

### ğŸ“‚ Verzeichnisstruktur

```text
.
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env
â”œâ”€â”€ backend/
â”œâ”€â”€ ollama-client/
â”œâ”€â”€ frontend/        # optional
â”œâ”€â”€ mosquitto/
â”‚   â””â”€â”€ config/mosquitto.conf
â”œâ”€â”€ shared/uploads/
```

---

## ğŸ³ Docker starten

```bash
docker compose up -d
```

**Wichtig:** Stelle sicher, dass dein NVIDIA-Toolkit korrekt installiert ist, falls du die GPU nutzen mÃ¶chtest (siehe unten).

---

## ğŸ§  GPU-Nutzung mit Ollama

### Voraussetzung

Damit der `ollama`-Container die GPU nutzen kann, muss **das NVIDIA Container Toolkit** installiert sein:

ğŸ‘‰ Anleitung:  
<https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html>

### PrÃ¼fung

```bash
docker info | grep -i nvidia
```

### Docker Compose Konfiguration (auszug)

```yaml
  ollama:
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
```

ğŸ’¡ Bei Problemen kannst du die Zeilen `runtime` und `deploy` auch auskommentieren, um Ollama nur mit CPU laufen zu lassen.

---

## ğŸŒ API-Endpunkte

- `POST /upload/` â€“ Bild hochladen
- `GET /images/` â€“ Liste aller Bilder mit Beschreibung

(Frontend-UI folgt)

---

## ğŸ›°ï¸ MQTT Topics

| Topic                            | Zweck                          |
|----------------------------------|---------------------------------|
| `smartoffice/image/uploaded`     | Wird vom Backend gesendet       |
| `smartoffice/image/described`    | Wird vom Ollama-Client verÃ¶ffentlicht |

---

## ğŸ“¦ Versionierung

Aktuelle Version: **v0.1 â€“ Rapid Prototype**

Geplant:

- [ ] Frontend (Upload + Vorschau)
- [ ] Ã„hnlichkeitsanalyse (FAISS)
- [ ] Automatisches Tagging
- [ ] Videoverarbeitung

---

## ğŸ§ª Test

Nach dem Start erreichst du das Backend unter:  
ğŸ“ <http://localhost:8000/docs> (Swagger-UI fÃ¼r API-Test)

---

## ğŸ§Š Kontakt / Weiterentwicklung

Ziel ist eine modulare, lokale oder cloudbasierte SmartOffice-LÃ¶sung fÃ¼r Einzelanwender und KMU.  
Fragen, Ideen oder Erweiterungen?
